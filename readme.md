<img src="./img/gif v1.gif" min-width="400px" max-width="400px" width="400px" align="right" alt="Computer iuriCode">
<p>
  <div align="right"> 
<a href="./readme.md"> <img src="./img/LogoUK.png" alt="Logo UK" width="30"/></a><a href="./leiame.md"> <img src="./img/logoBrazil.png" alt="Logo Brazil" width="30"/> </a>
</div>
  <H1><b> Victor Sérgio Silva Barros </b> </H1>
</p> 

<img src="./img/dio.png" alt="DIO Logo" width="200"/>
<img src="./img/artificial-intelligence.png" alt="Artificial Intelligence Logo" width="200"/>

# Calculation of Learning Evaluation Metrics

This project is based on the [DIO lab](https://web.dio.me/lab/calculo-de-metricas-de-avaliacao-de-aprendizado/learning/8c981faa-c9db-4a02-bad0-87035e170684).

## Overview

The calculation of learning evaluation metrics is essential to measure the performance of machine learning models. This project demonstrates how to calculate and interpret various evaluation metrics.

## Challenge Description

Calculation of Learning Evaluation Metrics

In this project, we will calculate the main metrics for evaluating data classification models, such as accuracy, sensitivity (recall), specificity, precision, and F-score. To implement these functions, you must use the methods and their corresponding formulas (Table 1).

To read the values of TP, TN, FP, and FN, it will be necessary to choose a confusion matrix as the basis for the calculations. This matrix can be chosen arbitrarily, as our goal is to understand how each metric works.

Table 1: Overview of the metrics used to evaluate classification methods. TP: true positives; FN: false negatives; FP: false positives; TN: true negatives; P: precision; S: sensitivity; N: total elements.

<img src="./img/Tabela 1.png" alt="Table 1" width="600"/>

## Requirements

- Python 3.x
- Scikit-learn
- NumPy
- Pandas
- Matplotlib

## Installation

1. Clone the repository:
    ```sh
    git clone https://github.com/your-repo/calculo-metricas-avaliacao.git
    ```
2. Navigate to the project directory:
    ```sh
    cd calculo-metricas-avaliacao
    ```
3. Install the required packages:
    ```sh
    pip install -r requirements.txt
    ```

## Usage

1. Prepare your dataset and place it in the `data` directory.
2. Run the metrics calculation script:
    ```sh
    python calcular_metricas.py
    ```

## Colab

You can also run the project using Google Colab. Open the following notebook in Colab:
[Metrics Calculation Notebook](notebooks/calculation_of_learning_evaluation_metrics.ipynb)

## Results

After execution, the model's performance will be evaluated, and the results will be displayed. You can visualize the training process and results using TensorBoard.

<img src= ./img/confusion-matrix.png />
<img src= ./img/TensorBoard.png /> 
<img src= ./img/ModelPerformanceMetrics.png /> 
## License

This project is licensed under the MIT license.

## Versioning

1.0.0

## Author

**Victor Sérgio Silva Barros**:

<p align="left">
  <a href="mailto:vicssb@gmail.com" alt="Gmail" target="_blank">
  <img src="https://img.shields.io/badge/-Gmail-FF0000?style=flat-square&labelColor=FF0000&logo=gmail&logoColor=white&link=mailto:vicssb@gmail.com" /></a>

  <a href="https://www.linkedin.com/in/victor-sergio-silva-barros/" alt="Linkedin" target="_blank">
  <img src="https://img.shields.io/badge/-Linkedin-0e76a8?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/victor-sergio-silva-barros/" /></a>

  <a href="https://wa.me/+5512981328278" alt="WhatsApp" target="_blank">
  <img src="https://img.shields.io/badge/-WhatsApp-25d366?style=flat-square&labelColor=25d366&logo=whatsapp&logoColor=white&link=https://wa.me/+5512987085327"/></a>

</p>

<p>Please follow GitHub and join us!
Thanks for visiting and happy coding!</p>